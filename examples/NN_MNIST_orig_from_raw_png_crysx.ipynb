{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb703b4",
   "metadata": {},
   "source": [
    "# This is a demo of how load to MNIST raw pngs manually without torchvision and use CrysX for neural network machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c9774",
   "metadata": {},
   "source": [
    "## Run the following for Google colab \n",
    "then restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --no-cache-dir https://github.com/manassharma07/crysx_nn/tarball/main\n",
    "! pip install IPython==7.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3fab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from crysx_nn import mnist_utils as mu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53199d0d",
   "metadata": {},
   "source": [
    "## Download MNIST_orig and MNIST_orig dataset  (May take upto 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81f600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu.downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede2f79",
   "metadata": {},
   "source": [
    "## Load the training dataset from MNIST_orig in memory (May take upto 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffade76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = 'MNIST-PLUS-PNG/mnist_orig_png'\n",
    "trainData, trainLabels = mu.loadMNIST(path_main=path, train=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b75697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (60000, 28, 28)\n",
      "Training labels shape (60000, 1)\n",
      "Size of training data in memory (GB) 0.3504753112792969\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape', trainData.shape)\n",
    "print('Training labels shape',trainLabels.shape)\n",
    "print('Size of training data in memory (GB)', trainData.nbytes/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0065b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "255.0\n",
      "33.318421449829934\n",
      "78.56748998339796\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.max()) # Expected for MNIST_orig: 255.\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 33.31842144\n",
    "print(trainData.std()) # Expected for MNIST_orig: 78.567489983"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637000b",
   "metadata": {},
   "source": [
    "## Normalize within the range [0,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9df9b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.13066047627384328\n",
      "0.3081078038564626\n"
     ]
    }
   ],
   "source": [
    "trainData = trainData/255 # Normalize\n",
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.max()) # Expected for MNIST_orig: 1.0\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 0.1306604762738426\n",
    "print(trainData.std()) # Expected for MNIST_orig: 0.3081078038564622 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ed0fd",
   "metadata": {},
   "source": [
    "## Standardize the data so that it has mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015a9fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4240738943915674\n",
      "2.8215433456893346\n",
      "-1.2434833208470416e-15\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "trainData = (trainData - np.mean(trainData)) / np.std(trainData)\n",
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: -0.42407\n",
    "print(trainData.max()) # Expected for MNIST_orig: 2.8215433\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.std()) # Expected for MNIST_orig: 1.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1b0af",
   "metadata": {},
   "source": [
    "## Convert labels to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1796640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.]\n",
      " [5.]\n",
      " [2.]\n",
      " ...\n",
      " [6.]\n",
      " [7.]\n",
      " [5.]]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainLabels)\n",
    "trainLabels = mu.one_hot_encode(trainLabels, 10)\n",
    "print(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b9d58",
   "metadata": {},
   "source": [
    "## Flatten the input numpy arrays (nSamples,28,28)->(nSamples, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70109dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.reshape(trainData.shape[0], 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f82965",
   "metadata": {},
   "source": [
    "## Let us create a NN using CrysX-NN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756390d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputs = 784 # No. of nodes in the input layer\n",
    "neurons_per_layer = [256, 10] # Neurons per layer (excluding the input layer)\n",
    "activation_func_names = ['ReLU', 'Softmax']\n",
    "nLayers = len(neurons_per_layer)\n",
    "nEpochs=15\n",
    "batchSize = 200 # No. of input samples to process at a time for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82e2b574",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'network' from 'crysx_nn' (C:\\Users\\manas\\anaconda3\\envs\\crysx_nn\\lib\\site-packages\\crysx_nn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13872/2621113092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcrysx_nn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnInputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnInputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons_per_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mneurons_per_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_func_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation_func_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'CPU'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Xavier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'network' from 'crysx_nn' (C:\\Users\\manas\\anaconda3\\envs\\crysx_nn\\lib\\site-packages\\crysx_nn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from crysx_nn import network\n",
    "model = network.nn_model(nInputs=nInputs, neurons_per_layer=neurons_per_layer, activation_func_names=activation_func_names, batch_size=batchSize, device='CPU', init_method='Xavier') \n",
    "\n",
    "model.lr = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0270e39f",
   "metadata": {},
   "source": [
    "## Check the model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332362bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d3820",
   "metadata": {},
   "source": [
    "## Optimize/Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c65fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = trainData.astype(np.float32)\n",
    "outputs = trainLabels.astype(np.float32)\n",
    "# Run optimization\n",
    "model.optimize(inputs, outputs, lr=0.4,nEpochs=nEpochs,loss_func_name='BCE', miniterEpoch=1, batchProgressBar=True, miniterBatch=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d111f5c",
   "metadata": {},
   "source": [
    "## Error at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d46b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26396396430333446, 0.09500577222506208, 0.06353291595379515, 0.04567561846574148, 0.03329302853345871, 0.024301023095846173, 0.017759342695275952, 0.013324549354116115, 0.01016170403907696, 0.007888218841453397, 0.006262726983427999, 0.005016529328624405, 0.004137800144652524, 0.00345419678688049, 0.002936867808302242]\n"
     ]
    }
   ],
   "source": [
    "print(model.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f7041f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025851249694824\n"
     ]
    }
   ],
   "source": [
    "from crysx_nn import loss\n",
    "### Baseline: just say it's anything at probability 1/N, what's the loss?\n",
    "N = 10\n",
    "labels = np.zeros((1, 10), dtype=np.float32)\n",
    "labels[0, 3] = 1.\n",
    "output = np.full_like(labels, 1./N)\n",
    "print(loss.CCE_loss(output, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ff259",
   "metadata": {},
   "source": [
    "## Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9261ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape (10000, 28, 28)\n",
      "Test labels shape (10000, 1)\n",
      "Size of training data in memory (GB) 0.05841255187988281\n",
      "0.0\n",
      "255.0\n",
      "33.791224489795916\n",
      "79.17246322228638\n",
      "0.0\n",
      "1.0\n",
      "0.13251460584233685\n",
      "0.31048024793053497\n",
      "5.136897709921942e-16\n",
      "0.9999999999999967\n",
      "0.13251460584233687\n",
      "0.31048024793053386\n",
      "[[5.]\n",
      " [3.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [3.]\n",
      " [1.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "path = 'MNIST-PLUS-PNG/mnist_orig_png'\n",
    "testData, testLabels = mu.loadMNIST(path_main=path, train=False, shuffle=True)\n",
    "\n",
    "print('Test data shape', testData.shape)\n",
    "print('Test labels shape',testLabels.shape)\n",
    "print('Size of training data in memory (GB)', testData.nbytes/1024/1024/1024)\n",
    "\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.max()) # Expected for MNIST_orig: 255.\n",
    "print(testData.mean()) # Expected for MNIST_orig: 33.31842144\n",
    "print(testData.std()) # Expected for MNIST_orig: 78.567489983\n",
    "\n",
    "## Normalize within the range [0,1.0]\n",
    "\n",
    "testData = testData/255 # Normalize\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.max()) # Expected for MNIST_orig: 1.0\n",
    "print(testData.mean()) # Expected for MNIST_orig: 0.1306604762738426\n",
    "print(testData.std()) # Expected for MNIST_orig: 0.3081078038564622 \n",
    "\n",
    "## Standardize the data so that it has mean 0 and variance 1\n",
    "# Use the mean and std of training data **********\n",
    "testData = (testData - np.mean(trainData)) / np.std(trainData)\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: -0.42407\n",
    "print(testData.max()) # Expected for MNIST_orig: 2.8215433\n",
    "print(testData.mean()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.std()) # Expected for MNIST_orig: 1.0000\n",
    "\n",
    "## Convert labels to one-hot vectors\n",
    "print(testLabels)\n",
    "testLabels = mu.one_hot_encode(testLabels, 10)\n",
    "print(testLabels)\n",
    "\n",
    "## Flatten the input numpy arrays (nSamples,28,28)->(nSamples, 784)\n",
    "testData = testData.reshape(testData.shape[0], 784)\n",
    "print(testData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72abe86",
   "metadata": {},
   "source": [
    "## Performance on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e291aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19892403373718268\n",
      "[[1.4272939e-04 3.1436319e-04 1.4046294e-02 ... 9.5708603e-01\n",
      "  3.8959793e-04 2.3934497e-04]\n",
      " [5.0430984e-04 3.4100066e-03 1.2485550e-03 ... 3.4560384e-03\n",
      "  1.2477242e-03 1.7275991e-02]\n",
      " [1.2849899e-03 3.5828482e-02 2.3844346e-02 ... 6.5003806e-03\n",
      "  1.6184315e-02 2.5329798e-02]\n",
      " ...\n",
      " [9.6470177e-01 5.5331498e-04 2.1353666e-02 ... 3.5619541e-04\n",
      "  7.2536396e-04 1.2194988e-03]\n",
      " [8.3557570e-06 1.9223923e-04 7.0760906e-04 ... 5.2572825e-05\n",
      "  6.2861788e-04 4.1355952e-04]\n",
      " [2.7002022e-03 8.7708443e-01 5.1665306e-02 ... 4.4485386e-02\n",
      "  3.6999616e-03 7.3504559e-04]]\n"
     ]
    }
   ],
   "source": [
    "## Convert to float32 arrays\n",
    "inputs = testData.astype(np.float32)\n",
    "outputs = testLabels.astype(np.float32)\n",
    "predictions, error = model.predict(inputs, outputs, loss_func_name='CCE')\n",
    "print(error)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb79a7",
   "metadata": {},
   "source": [
    "## Interactive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "974f49b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04333514 0.03457133 0.02409214 0.42535805 0.0381371  0.03144073\n",
      "  0.02143424 0.03070122 0.16689689 0.18403316]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import cv2\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "white = (255, 255, 255) # canvas back\n",
    "\n",
    "def save():\n",
    "    # save image to hard drive\n",
    "    filename = \"user_input.jpg\"\n",
    "    global output_image \n",
    "    output_image.save(filename)\n",
    "    ###### Centering begin\n",
    "    # Load image as grayscale and obtain bounding box coordinates\n",
    "    image = cv2.imread('user_input.jpg', 0)\n",
    "#     print(image)\n",
    "    height, width = image.shape\n",
    "    x,y,w,h = cv2.boundingRect(image)\n",
    "\n",
    "    # Create new blank image and shift ROI to new coordinates\n",
    "    ROI = image[y:y+h, x:x+w]\n",
    "    mask = np.zeros([ROI.shape[0]+10,ROI.shape[1]+10])\n",
    "    width, height = mask.shape\n",
    "#     print(ROI.shape)\n",
    "#     print(mask.shape)\n",
    "    x = width//2 - ROI.shape[0]//2 \n",
    "    y = height//2 - ROI.shape[1]//2 \n",
    "#     print(x,y)\n",
    "    mask[y:y+h, x:x+w] = ROI\n",
    "#     print(mask)\n",
    "    # Check if centering/masking was successful\n",
    "#     plt.imshow(mask, cmap='viridis') \n",
    "    output_image = PIL.Image.fromarray(mask) # mask has values in [0-255] as expected\n",
    "# Now we need to resize, but it causes problems with default arguments as it changes the range of pixel values to be negative or positive\n",
    "    # compressed_output_image = output_image.resize((22,22))\n",
    "    # Therefore, we use the following:\n",
    "    compressed_output_image = output_image.resize((22,22), PIL.Image.BILINEAR) # PIL.Image.NEAREST or PIL.Image.BILINEAR also performs good\n",
    "\n",
    "#     # Enhance Saturation\n",
    "#     converter = PIL.ImageEnhance.Color(compressed_output_image)\n",
    "#     compressed_output_image = converter.enhance(2.5)\n",
    "    # Enhance contrast\n",
    "#     converter = PIL.ImageEnhance.Contrast(compressed_output_image)\n",
    "#     compressed_output_image = converter.enhance(3.5)\n",
    "    # normalize in the range 0-1\n",
    "    tensor_image = np.array(compressed_output_image.getdata())/255.\n",
    "    tensor_image = tensor_image.reshape(22,22)\n",
    "    # Padding\n",
    "    tensor_image = np.pad(tensor_image, (3,3), \"constant\", constant_values=(0,0))\n",
    "    # Normalization should be done after padding i guess\n",
    "    tensor_image = (tensor_image - np.mean(trainData)) / np.std(trainData)\n",
    "    plt.imshow(tensor_image.reshape(28,28), cmap='viridis')\n",
    "    # Debugging\n",
    "#     print(tensor_image)\n",
    "#     print(np.array(compressed_output_image.getdata())) # Get data values)\n",
    "#     print(np.array(image.getdata()))\n",
    "\n",
    "    ### Compute the predictions\n",
    "    output0 = model.predict(tensor_image.reshape(1,784))\n",
    "    print(output0)\n",
    "    output = np.argmax(output0)\n",
    "    print(output)\n",
    "    \n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "#     canvas.create_oval(x1, y1, x2, y2, fill=\"white\",width=24)\n",
    "    canvas.create_rectangle(x1, y1, x2, y2, fill=\"white\",width=12)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"white\",width=4)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# create a tkinter canvas to draw on\n",
    "canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "# create an empty PIL image and draw object to draw on\n",
    "output_image = PIL.Image.new(\"L\", (width, height), 0)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "canvas.pack(expand=YES, fill=BOTH)\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "# add a button to save the image\n",
    "button=Button(text=\"save\",command=save)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2a2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
