{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb703b4",
   "metadata": {},
   "source": [
    "# This is a demo of how to load MNIST raw pngs manually and use CrysX for neural network machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c925c8",
   "metadata": {},
   "source": [
    "## Run the following for Google colab \n",
    "then restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --no-cache-dir https://github.com/manassharma07/crysx_nn/tarball/main\n",
    "! pip install IPython==7.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d3fab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from crysx_nn import mnist_utils as mu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2973a31",
   "metadata": {},
   "source": [
    "## Download MNIST_orig and MNIST_plus dataset (May take upto 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afde5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mu.downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7de5a",
   "metadata": {},
   "source": [
    "## Load the training dataset from MNIST_plus in memory (May take upto 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffade76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = 'MNIST-PLUS-PNG/mnist_plus_png'\n",
    "trainData, trainLabels = mu.loadMNIST(path_main=path, train=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b75697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape', trainData.shape)\n",
    "print('Training labels shape',trainLabels.shape)\n",
    "print('Size of training data in memory (GB)', trainData.nbytes/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.max()) # Expected for MNIST_orig: 255.\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 33.31842144\n",
    "print(trainData.std()) # Expected for MNIST_orig: 78.567489983"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a637000b",
   "metadata": {},
   "source": [
    "## Normalize within the range [0,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData/255 # Normalize\n",
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.max()) # Expected for MNIST_orig: 1.0\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 0.1306604762738426\n",
    "print(trainData.std()) # Expected for MNIST_orig: 0.3081078038564622 \n",
    "\n",
    "trainData_mean = trainData.mean()\n",
    "trainData_std = trainData.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ed0fd",
   "metadata": {},
   "source": [
    "## Standardize the data so that it has mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = (trainData - np.mean(trainData)) / np.std(trainData)\n",
    "# Statistics\n",
    "print(trainData.min()) # Expected for MNIST_orig: -0.42407\n",
    "print(trainData.max()) # Expected for MNIST_orig: 2.8215433\n",
    "print(trainData.mean()) # Expected for MNIST_orig: 0.0\n",
    "print(trainData.std()) # Expected for MNIST_orig: 1.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1b0af",
   "metadata": {},
   "source": [
    "## Convert labels to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1796640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainLabels)\n",
    "trainLabels = mu.one_hot_encode(trainLabels, 10)\n",
    "print(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c8407",
   "metadata": {},
   "source": [
    "## Flatten the input numpy arrays (nSamples,28,28)->(nSamples, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70109dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.reshape(trainData.shape[0], 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f82965",
   "metadata": {},
   "source": [
    "## Let us create a NN using CrysX-NN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756390d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputs = 784 # No. of nodes in the input layer\n",
    "neurons_per_layer = [256, 10] # Neurons per layer (excluding the input layer)\n",
    "activation_func_names = ['ReLU', 'Softmax']\n",
    "nLayers = len(neurons_per_layer)\n",
    "nEpochs = 8\n",
    "batchSize = 32 # No. of input samples to process at a time for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80740bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crysx_nn import network\n",
    "model = network.nn_model(nInputs=nInputs, neurons_per_layer=neurons_per_layer, activation_func_names=activation_func_names, batch_size=batchSize, device='CPU', init_method='Xavier') \n",
    "\n",
    "model.lr = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f95885",
   "metadata": {},
   "source": [
    "## Check the model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d70f66",
   "metadata": {},
   "source": [
    "## Optimize/Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6931984",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = trainData.astype(np.float32)\n",
    "outputs = trainLabels.astype(np.float32)\n",
    "# Run optimization\n",
    "# model.optimize(inputs, outputs, lr=0.4,nEpochs=nEpochs,loss_func_name='BCE', miniterEpoch=1, batchProgressBar=True, miniterBatch=100)\n",
    "# To get accuracies at each epoch\n",
    "model.optimize(inputs, outputs, lr=0.4,nEpochs=nEpochs,loss_func_name='CCE', miniterEpoch=1, batchProgressBar=True, miniterBatch=100, get_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6156fb",
   "metadata": {},
   "source": [
    "## Error at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f84ba",
   "metadata": {},
   "source": [
    "## Accuracy at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a03f5",
   "metadata": {},
   "source": [
    "## Save model weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "model.save_model_weights('NN_crysx_mnist_plus_98.11_weights')\n",
    "# Save biases\n",
    "model.save_model_biases('NN_crysx_mnist_plus_98.11_biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0fbdd",
   "metadata": {},
   "source": [
    "## Load model weights and biases from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099287ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model_weights('NN_crysx_mnist_plus_98.11_weights')\n",
    "model.load_model_biases('NN_crysx_mnist_plus_98.11_biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7041f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crysx_nn import loss\n",
    "### Baseline: just say it's anything at probability 1/N, what's the loss?\n",
    "N = 10\n",
    "labels = np.zeros((1, 10), dtype=np.float32)\n",
    "labels[0, 3] = 1.\n",
    "output = np.full_like(labels, 1./N)\n",
    "print(loss.BCE_loss(output, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ff259",
   "metadata": {},
   "source": [
    "## Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MNIST-PLUS-PNG/mnist_plus_png'\n",
    "testData, testLabels = mu.loadMNIST(path_main=path, train=False, shuffle=True)\n",
    "\n",
    "print('Test data shape', testData.shape)\n",
    "print('Test labels shape',testLabels.shape)\n",
    "print('Size of training data in memory (GB)', testData.nbytes/1024/1024/1024)\n",
    "\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.max()) # Expected for MNIST_orig: 255.\n",
    "print(testData.mean()) # Expected for MNIST_orig: 33.31842144\n",
    "print(testData.std()) # Expected for MNIST_orig: 78.567489983\n",
    "\n",
    "## Normalize within the range [0,1.0]\n",
    "\n",
    "testData = testData/255 # Normalize\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.max()) # Expected for MNIST_orig: 1.0\n",
    "print(testData.mean()) # Expected for MNIST_orig: 0.1306604762738426\n",
    "print(testData.std()) # Expected for MNIST_orig: 0.3081078038564622 \n",
    "\n",
    "## Standardize the data so that it has mean 0 and variance 1\n",
    "# Use the mean and std of training data **********\n",
    "testData = (testData - trainData_mean) / trainData_std\n",
    "# Statistics\n",
    "print(testData.min()) # Expected for MNIST_orig: -0.42407\n",
    "print(testData.max()) # Expected for MNIST_orig: 2.8215433\n",
    "print(testData.mean()) # Expected for MNIST_orig: 0.0\n",
    "print(testData.std()) # Expected for MNIST_orig: 1.0000\n",
    "\n",
    "## Convert labels to one-hot vectors\n",
    "print(testLabels)\n",
    "testLabels = mu.one_hot_encode(testLabels, 10)\n",
    "print(testLabels)\n",
    "\n",
    "## Flatten the input numpy arrays (nSamples,28,28)->(nSamples, 784)\n",
    "testData = testData.reshape(testData.shape[0], 784)\n",
    "print(testData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72abe86",
   "metadata": {},
   "source": [
    "## Performance on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e291aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Convert to float32 arrays\n",
    "inputs = testData.astype(np.float32)\n",
    "outputs = testLabels.astype(np.float32)\n",
    "predictions, error = model.predict(inputs, outputs, loss_func_name='CCE')\n",
    "print('Error:',error)\n",
    "# print(predictions)\n",
    "predictions, error, accuracy = model.predict(inputs, outputs, loss_func_name='CCE', get_accuracy=True)\n",
    "print('Error:',error)\n",
    "print('Accuracy %:',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bed807",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crysx_nn import utils\n",
    "\n",
    "# Get the indices of the maximum probabilities for each sample in the predictions array\n",
    "pred_digit = np.argmax(predictions, axis=1)\n",
    "# Get the digit index from the one-hot encoded array\n",
    "true_digit = np.argmax(testLabels, axis=1)\n",
    "# Calculation confusion matrix\n",
    "cm = utils.compute_confusion_matrix(pred_digit, true_digit)\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.rcParams[\"figure.figsize\"] = (14,10)\n",
    "utils.plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb79a7",
   "metadata": {},
   "source": [
    "## Interactive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "974f49b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all the digits:\n",
      "[[7.17646448e-07 1.78607763e-04 5.82082371e-06 6.28835313e-01\n",
      "  2.67098937e-05 3.54523342e-03 1.91294708e-05 3.66894452e-01\n",
      "  3.06669355e-11 4.94015713e-04]]\n",
      "Prediction\n",
      "3\n",
      "Top 3 predictions\n",
      "[3 7 5]\n",
      "Their probabilities (%)\n",
      "[62.88353133 36.68944519  0.35452334]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import cv2\n",
    "\n",
    "width = 200  # canvas width\n",
    "height = 200 # canvas height\n",
    "center = height//2\n",
    "white = (255, 255, 255) # canvas back\n",
    "\n",
    "def save():\n",
    "    # save image to hard drive\n",
    "    filename = \"user_input.jpg\"\n",
    "    global output_image \n",
    "    output_image.save(filename)\n",
    "    ###### Centering begin\n",
    "    # Load image as grayscale and obtain bounding box coordinates\n",
    "    image = cv2.imread('user_input.jpg', 0)\n",
    "#     print(image)\n",
    "    height, width = image.shape\n",
    "    x,y,w,h = cv2.boundingRect(image)\n",
    "\n",
    "    # Create new blank image and shift ROI to new coordinates\n",
    "    ROI = image[y:y+h, x:x+w]\n",
    "    mask = np.zeros([ROI.shape[0]+10,ROI.shape[1]+10])\n",
    "    width, height = mask.shape\n",
    "#     print(ROI.shape)\n",
    "#     print(mask.shape)\n",
    "    x = width//2 - ROI.shape[0]//2 \n",
    "    y = height//2 - ROI.shape[1]//2 \n",
    "#     print(x,y)\n",
    "    mask[y:y+h, x:x+w] = ROI\n",
    "#     print(mask)\n",
    "    # Check if centering/masking was successful\n",
    "#     plt.imshow(mask, cmap='viridis') \n",
    "    output_image = PIL.Image.fromarray(mask) # mask has values in [0-255] as expected\n",
    "# Now we need to resize, but it causes problems with default arguments as it changes the range of pixel values to be negative or positive\n",
    "    # compressed_output_image = output_image.resize((22,22))\n",
    "    # Therefore, we use the following:\n",
    "    compressed_output_image = output_image.resize((22,22), PIL.Image.BILINEAR) # PIL.Image.NEAREST or PIL.Image.BILINEAR also performs good\n",
    "\n",
    "#     # Enhance Saturation\n",
    "#     converter = PIL.ImageEnhance.Color(compressed_output_image)\n",
    "#     compressed_output_image = converter.enhance(2.5)\n",
    "    # Enhance contrast\n",
    "#     converter = PIL.ImageEnhance.Contrast(compressed_output_image)\n",
    "#     compressed_output_image = converter.enhance(3.5)\n",
    "    # normalize in the range 0-1\n",
    "    tensor_image = np.array(compressed_output_image.getdata())/255.\n",
    "    tensor_image = tensor_image.reshape(22,22)\n",
    "    # Padding\n",
    "    tensor_image = np.pad(tensor_image, (3,3), \"constant\", constant_values=(0,0))\n",
    "    # Normalization should be done after padding i guess\n",
    "    tensor_image = (tensor_image - trainData_mean) / trainData_std\n",
    "    plt.imshow(tensor_image.reshape(28,28), cmap='viridis')\n",
    "    # Debugging\n",
    "#     print(tensor_image)\n",
    "#     print(np.array(compressed_output_image.getdata())) # Get data values)\n",
    "#     print(np.array(image.getdata()))\n",
    "\n",
    "    ### Compute the predictions\n",
    "    output0 = model.predict(tensor_image.reshape(1,784))\n",
    "    print('Probabilities for all the digits:')\n",
    "    print(output0)\n",
    "    output = np.argmax(output0)\n",
    "    print('Prediction')\n",
    "    print(output)\n",
    "    print('Top 3 predictions')\n",
    "    print(output0[0].argsort()[-3:][::-1])\n",
    "    print('Their probabilities (%)')\n",
    "    ind = output0[0].argsort()[-3:][::-1]\n",
    "    print(output0[0,ind]*100)\n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "#     canvas.create_oval(x1, y1, x2, y2, fill=\"white\",width=24)\n",
    "    canvas.create_rectangle(x1, y1, x2, y2, fill=\"white\",width=12)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"white\",width=4)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# create a tkinter canvas to draw on\n",
    "canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "# create an empty PIL image and draw object to draw on\n",
    "output_image = PIL.Image.new(\"L\", (width, height), 0)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "canvas.pack(expand=YES, fill=BOTH)\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "# add a button to save the image\n",
    "button=Button(text=\"save\",command=save)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3b1da",
   "metadata": {},
   "source": [
    "## Inference with 256 nodes; lr=0.4, 15 epochs:\n",
    "recognition of 1 has significantly improved in MNIST_PLus, but when it has both the above and bottom additional lines then it gets classified as 3 for some reason. Although, 1 with just the upper additional line is predicted correctly.\n",
    "\n",
    "\n",
    "Prediction of 7 is now massively improved when using MNIST_plus. It is amazing.\n",
    "\n",
    "Classification of 2, 3, 4, 5, 6, 7, 8, and 9 are no problem.\n",
    "\n",
    "## Inference with 512 nodes; lr=0.7, 15 epochs:\n",
    "Now 1 is predicted correctly most of the times.\n",
    "\n",
    "But 8 can be a problem sometimes.\n",
    "\n",
    "Classification of 1, 2, 3, 4, 5, 6, 7, and 9 are no problem.\n",
    "\n",
    "## Inference with 256 nodes; lr=0.4; just 5 epochs:\n",
    "It seems like earlier we were running into some overfitting issues when going to 15 epochs. Even 5 epochs seem to be causing overkill as the training accuracy surpasses testing accuracy after just 3 epochs. \n",
    "\n",
    "When using just 5 epochs there are no issues in the prediction of 1 or 8 as in the above cases.\n",
    "\n",
    "In fact, all the digits are recognized reasonably correctly except 8 which got confuesed with 5, 7 and 6 sometimes.\n",
    "(Sometimes 9 was mistaken for 4 as well)\n",
    "\n",
    "Although, the confidence of the result is not as good as what you get with CNNs.\n",
    "\n",
    "## Inference with 256 nodes; lr=0.4;  7 epochs:\n",
    "2 was predicted as 7 sometimes\n",
    "\n",
    "3 was predicted as 5 sometimes\n",
    "\n",
    "4 was predicted as 6,1,2  or 5\n",
    "\n",
    "## Inference with 256 nodes; lr=0.4;  10 epochs:\n",
    "1 was predicted correctly as long as it didnt have a too long bottom underline\n",
    "\n",
    "4 was a bit problematic.\n",
    "\n",
    "2 was a bit problematic.\n",
    "\n",
    "## Inference with 256 nodes; lr=0.4;  20 epochs:\n",
    "4 was a bit problematic.\n",
    "\n",
    "The problem with 1 underline was gone.\n",
    "\n",
    "2 was a bit problematic.\n",
    "\n",
    "## Inference with 256 nodes; lr=0.4;  30 epochs:\n",
    "4 was a bit problematic.\n",
    "\n",
    "9 was a bit problematic.\n",
    "\n",
    "8 was a bit problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092854a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
